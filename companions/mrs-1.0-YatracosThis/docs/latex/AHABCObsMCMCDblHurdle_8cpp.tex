\hypertarget{AHABCObsMCMCDblHurdle_8cpp}{\subsection{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp \-File \-Reference}
\label{AHABCObsMCMCDblHurdle_8cpp}\index{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp@{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp}}
}
{\ttfamily \#include $<$iomanip$>$}\*
{\ttfamily \#include $<$time.\-h$>$}\*
{\ttfamily \#include $<$fstream$>$}\*
{\ttfamily \#include $<$sstream$>$}\*
{\ttfamily \#include $<$map$>$}\*
{\ttfamily \#include $<$iterator$>$}\*
{\ttfamily \#include \char`\"{}histall.\-hpp\char`\"{}}\*
{\ttfamily \#include \char`\"{}dataprep.\-hpp\char`\"{}}\*
{\ttfamily \#include \char`\"{}\-Small\-Classes.\-hpp\char`\"{}}\*
{\ttfamily \#include \char`\"{}\-M\-C\-M\-C\-G\-Rtools.\-hpp\char`\"{}}\*
{\ttfamily \#include $<$stdexcept$>$}\*
{\ttfamily \#include $<$functional$>$}\*
{\ttfamily \#include $<$algorithm$>$}\*
{\ttfamily \#include $<$cassert$>$}\*
\subsubsection*{\-Defines}
\begin{DoxyCompactItemize}
\item 
\#define \hyperlink{AHABCObsMCMCDblHurdle_8cpp_a38cc676e6c9f06e021b17e537b7bba1d}{\-M\-Y\-D\-E\-B\-U\-G}
\end{DoxyCompactItemize}
\subsubsection*{\-Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classsubpavings_1_1AdaptiveHistogramCollator}{\-Adaptive\-Histogram\-Collator} \hyperlink{AHABCObsMCMCDblHurdle_8cpp_abcb1c598d5fc24ad761d43c1855103ea}{do\-M\-C\-M\-C\-G\-R\-Auto} (string dir\-Name, string sim\-Data\-Files, string obs\-Data\-File, double wt, double dx, int max\-Loops, int samples\-Needed, int thinout, int min\-Points, cxsc\-::real tol\-\_\-leaves, cxsc\-::real tol\-\_\-\-L1, int rhat\-Flag\-Counter\-Threshold, int start\-With\-Full\-Checks=0)
\item 
int \hyperlink{AHABCObsMCMCDblHurdle_8cpp_a0ddf1224851353fc92bfbff6f499fa97}{main} (int argc, char $\ast$argv\mbox{[}$\,$\mbox{]})
\end{DoxyCompactItemize}


\subsubsection{\-Define \-Documentation}
\hypertarget{AHABCObsMCMCDblHurdle_8cpp_a38cc676e6c9f06e021b17e537b7bba1d}{\index{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp@{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp}!\-M\-Y\-D\-E\-B\-U\-G@{\-M\-Y\-D\-E\-B\-U\-G}}
\index{\-M\-Y\-D\-E\-B\-U\-G@{\-M\-Y\-D\-E\-B\-U\-G}!AHABCObsMCMCDblHurdle.cpp@{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp}}
\paragraph[{\-M\-Y\-D\-E\-B\-U\-G}]{\setlength{\rightskip}{0pt plus 5cm}\#define {\bf \-M\-Y\-D\-E\-B\-U\-G}}}\label{AHABCObsMCMCDblHurdle_8cpp_a38cc676e6c9f06e021b17e537b7bba1d}


\-Definition at line 45 of file \-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp.



\subsubsection{\-Function \-Documentation}
\hypertarget{AHABCObsMCMCDblHurdle_8cpp_abcb1c598d5fc24ad761d43c1855103ea}{\index{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp@{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp}!do\-M\-C\-M\-C\-G\-R\-Auto@{do\-M\-C\-M\-C\-G\-R\-Auto}}
\index{do\-M\-C\-M\-C\-G\-R\-Auto@{do\-M\-C\-M\-C\-G\-R\-Auto}!AHABCObsMCMCDblHurdle.cpp@{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp}}
\paragraph[{do\-M\-C\-M\-C\-G\-R\-Auto}]{\setlength{\rightskip}{0pt plus 5cm}{\bf \-Adaptive\-Histogram\-Collator} {\bf do\-M\-C\-M\-C\-G\-R\-Auto} (
\begin{DoxyParamCaption}
\item[{string}]{dir\-Name, }
\item[{string}]{sim\-Data\-Files, }
\item[{string}]{obs\-Data\-File, }
\item[{double}]{wt, }
\item[{double}]{dx, }
\item[{int}]{max\-Loops, }
\item[{int}]{samples\-Needed, }
\item[{int}]{thinout, }
\item[{int}]{min\-Points, }
\item[{cxsc\-::real}]{tol\-\_\-leaves, }
\item[{cxsc\-::real}]{tol\-\_\-\-L1, }
\item[{int}]{rhat\-Flag\-Counter\-Threshold, }
\item[{int}]{start\-With\-Full\-Checks = {\ttfamily 0}}
\end{DoxyParamCaption}
)}}\label{AHABCObsMCMCDblHurdle_8cpp_abcb1c598d5fc24ad761d43c1855103ea}


\-Definition at line 140 of file \-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp.



\-References add\-Data\-Ptrs(), subpavings\-::\-Adaptive\-Histogram\-Collator\-::add\-To\-Collation(), subpavings\-::\-S\-Pnode\-::get\-Box(), subpavings\-::\-Adaptive\-Histogram\-Collator\-::get\-Est\-Log\-Likelihood\-From\-R\-S\-Sample(), subpavings\-::\-Adaptive\-Histogram\-Collator\-::get\-Number\-Collated(), subpavings\-::\-Adaptive\-Histogram\-::get\-Sub\-Paving(), subpavings\-::\-Adaptive\-Histogram\-::insert\-From\-R\-S\-Sample(), subpavings\-::\-Adaptive\-Histogram\-::insert\-From\-R\-Vec(), \-Lab\-Pnt\-::\-L, subpavings\-::label\-Data\-From\-Filter(), taylor\-::\-Lb(), subpavings\-::\-L\-O\-G\-S\-A\-M\-P\-L\-E\-S, subpavings\-::\-Adaptive\-Histogram\-Collator\-::make\-Average(), subpavings\-::\-N\-O\-L\-O\-G, subpavings\-::\-Adaptive\-Histogram\-Collator\-::output\-Average\-To\-Txt\-Tabs(), subpavings\-::output\-File\-Start(), output\-To\-File\-Vertical(), subpavings\-::\-Adaptive\-Histogram\-Collator\-::output\-To\-Txt\-Tabs(), \-Lab\-Pnt\-::\-Pnt, subpavings\-::point\-Mass\-Filter(), subpavings\-::\-Adaptive\-Histogram\-::priority\-Split(), subpavings\-::\-Adaptive\-Histogram\-Collator\-::public\-Output\-Log(), subpavings\-::read\-Rvectors\-From\-Txt(), \-R\-S\-Sample\-::\-Samples, and taylor\-::\-Ub().



\-Referenced by main().


\begin{DoxyCode}
{
  //=========Some preliminaries for AHABC==================================//
   //set formatting fors input to oss
    ofstream os;         // ofstream object
    os << scientific;  // set formatting for input to oss
    os.precision(16);
   
   // set up a random number generator for uniform rvs in priority queue
    const gsl_rng_type * T;
    gsl_rng * r;
    //create a generator chosen by the environment variable GSL_RNG_TYPE
    gsl_rng_env_setup();
    T = gsl_rng_default;
    r = gsl_rng_alloc (T);
    long s = time (NULL) * getpid();
    gsl_rng_set(r, s);

   //-------Setup to read in data files------------------------------------//
   //Read in simulated files
  //create a vector object to store the filenames of simulated data
  vector<string> simDataFilesVec;
  string fileName;
  cout << "Reading in file names for simulated data: " << endl;    
  ifstream file; // create file for input
  file.open(simDataFiles.c_str());
  // check if this file exists or not
  if ( !file ) { // exit if file doesn't exists'
    cerr << "Could not open " << simDataFiles << ". It does not exist." 
         << endl;
    exit(1);
  }
    // else read in the filenames
  // store the filenames in the vector simDataFilesVec
  while ( !file.eof() ) { // read until end of file or error
    file >> fileName;
    cout << fileName << endl; 
    simDataFilesVec.push_back(fileName);
  }
  // Somehow an extra line will be read in. Need to delete that extra line.
  simDataFilesVec.pop_back();
  
  //Read in observed files
  //create a container to keep observed data
  RVecData obsData;
  
  //container to keep individual data containers
  vector<RVecData> unlabDataVec; //unlabelled data

   //container to keep both simulated and observed data to make root box
   RVecData* dataPtr;
  dataPtr = new RVecData; 
  
  // put all simulated data into container pointed to by dataPtr
  cout << "\nPut simulated data in a container to get rootbox: " << endl;   
  for (size_t i = 0;  i < simDataFilesVec.size(); i++) {
    cout << simDataFilesVec[i] << endl;
    //read into allData
    bool retvalue = readRvectorsFromTxt((*dataPtr), simDataFilesVec[i], 0);
    if (retvalue == false)  {
      cerr << "Could not open " << simDataFiles << ". It does not exist." 
        << endl;
      exit(1);
    } 
      //cout << (*(dataPtr)).size() << "is the size of dataPtr at iteration "
       << i << endl;
    //Then read each data set and push into unlabDataVec 
     cout << "\nPut simulated data in container for filtering and labelling: " 
      << endl;
    RVecData unlabIndData;
    readRvectorsFromTxt(unlabIndData, simDataFilesVec[i], 0);
    unlabDataVec.push_back(unlabIndData);
  }
  
  //put observed data into container pointed to by dataPtr
  cout << "\nPut observed data in container with simulated data to get rootbox:
      " 
      << endl;
  bool retvalue = readRvectorsFromTxt((*dataPtr), obsDataFile, 0);
  if (retvalue == false)  {
      cerr << "Could not open " << obsDataFile << ". It does not exist." 
        << endl;
      exit(1);
  }
  //find the data dimensions from the first datapoint
  size_t dataDim = Ub(*(*dataPtr).begin()) - Lb(*(*dataPtr).begin()) + 1;
  cout << "Data has " << dataDim << " dimensions." << endl;

  //also read into obsData container
  cout << "\nPut observed data in container for observed data only" << endl;
  readRvectorsFromTxt(obsData, obsDataFile, 0);
  //point mass filtering and data labelling for observed data
  RSSample labObsData;
  if (dataDim == 1) { // only filter for 1D
    map<rvector, size_t, less<rvector> > CountsMap;   
    //run a point mass filter to get "atomic" points
    cout << "run point mass filter over observed data:" << endl;
    pointMassFilter(obsData, CountsMap);
    //EMFMap is not needed anymore actually - will see how i can turn it off or
       do something else
       //TODO: see TODO comment in "../../../src/sptools.cpp" 1220ish Line
    map<rvector, double, less<rvector> > EMFMap; 
    cout << "label data" << endl;
    labelDataFromFilter(obsData, labObsData, CountsMap, EMFMap);
  }
  else { // for now make RVecData into RSSample object for higher dim
     //TODO: This can be done (not for GT's PhD necessarily) "trans-dimensional
       density estimation!"
     //this is a beautiful extension of estimating axis-parallel
       low-dimensional atomic densities 
     //inside root box in R^d or other subsets specified by prior constraints
    RVecData::iterator it;
    for (it = obsData.begin(); it < obsData.end(); it++) {
        LabPnt labThisData;
        labThisData.Pnt = (*it);
        labThisData.L = 1;
        //labThisData.Print(cout);
        labObsData.Samples.push_back(labThisData);
    }
  } // end of labelling observed data
    
  //Make root box from ALL the data
  cout << "\n" << endl;
  AdaptiveHistogram* histRoot;
  histRoot = new AdaptiveHistogram;
   //cout << (*(dataPtr)).size() << "is the size of dataPtr AFTER iteration " 
       << endl;
  histRoot->insertFromRVec((*dataPtr));
  ivector pavingBox = histRoot->getSubPaving()->getBox();
  
  delete dataPtr; //we do not need this in memory
  delete histRoot; //we do not need this in memory
  //-----end of setup to read in data files-------------------------------//
  
  //----go through each RVecData in unlabData for the following:------------//
  //1. point mass filtering
  //2. build histogram  
  //3. put observed data into histogram
  //4. get estimated log-likelihood
  
  //Set up containers to contain weights for each mixture model
  vector< map<rvector, double, less<rvector> > > WeightPMVec;//for point mass
  vector<double> WeightHistVec; //for histogram
  
  //Set up containers to contain log-likelihood for the observed data
  //for each histogram 
  vector<real> logLikVec;
  
  //Now loop through each RVecData
  vector<RVecData>::iterator unlabDataIt;
  RVecData::iterator dataIt;
  size_t D = 0;
  for (unlabDataIt = unlabDataVec.begin(); unlabDataIt < unlabDataVec.end(); 
      unlabDataIt++) 
  {
    ostringstream stmD;
    stmD << D+1;
    cout << "==============Simulated Data " << D+1 << "==========" << endl;
    //---------point mass filtering and data labelling-------------//
    //simulated data
    RSSample labData; //for point mass filtering 
    if (dataDim == 1) { //for now, do this only in 1D
      //make a map for value of x (the key) and each of its respective 
      //counts (the value)
      map<rvector, size_t, less<rvector> > CountsMap;   
      //run a point mass filtering to get "atomic" points
      pointMassFilter((*unlabDataIt), CountsMap);
      //Is there a more efficient way for the labelling:
      //Iterate through the data set again. Label point-mass with 0 and 
      //the rest with 1.
      //Also get a map for the EMF of  point mass data
      map<rvector,double, less<rvector> > EMFMap;
      map<rvector, double, less<rvector> >::iterator EMFMapIt;
      labelDataFromFilter((*unlabDataIt), labData, CountsMap, EMFMap);
            
      /*optional: output RSSample this to .txt
      vector<LabPnt>::iterator LabPntIt; //to iterate over labData.Samples
      string fileName = "Labelled";
      fileName += simDataFilesVec[D];
      oftream os;
      os.open(fileName.c_str());
      for (LabPntIt = labData.Samples.begin(); LabPntIt <
       labData.Samples.end();
          LabPntIt++) {
        (*LabPntIt).Print(os);
      }
      os << flush;
      */ //end of optional output
      
      //Store the weights
      cout << "Atomic points and their EMFs" << endl;
      double pmWeight = 0.0;
      double MaxpmWeight = 0.0;
      rvector AtomWithMaxpm = EMFMap.begin()->first;
      for (EMFMapIt = EMFMap.begin(); EMFMapIt != EMFMap.end(); EMFMapIt++) {
        if(EMFMapIt->second > MaxpmWeight) 
          {//a messy way to keep the max atom and weight...
           MaxpmWeight=EMFMapIt->second;
           AtomWithMaxpm = EMFMapIt->first;
          }
        pmWeight += EMFMapIt->second;
        if( EMFMapIt->second < 0.0)// use < to skip the ? below
          {
           cout << setprecision(16) << EMFMapIt->first 
           << "\t" << EMFMapIt->second << endl;
           cout << "is this atomic in your experimental precision?" << endl; 
           getchar();
          }
      }
      cout << "Maximum Weight of a set of Atoms of size "<< EMFMap.size() 
        << " is " << MaxpmWeight << " at " << AtomWithMaxpm << endl;
      WeightHistVec.push_back(1.0 - pmWeight);
      WeightPMVec.push_back(EMFMap);
      
       //output the weights for the point mass so that we can plot the point
       mass
        //and the normalised histogram
        string weightFileName = dirName;
        weightFileName += "Weights";
      ostringstream stm1;
      stm1 << D;
      weightFileName += stm1.str();
      weightFileName += ".txt";
      os.open(weightFileName.c_str());
      map<rvector, double, less<rvector> > ::iterator mapIt;
      for (mapIt = (EMFMap).begin(); mapIt != (EMFMap).end(); mapIt++) {
        os << mapIt->second << "\t" << mapIt->first;
      }
       os << endl;
      os << flush;
       os.close();
       cout << "Weights output to " << weightFileName << endl; 
       cout << "=================================================" << endl;
    
    } // end of point mass filtering for 1D

    cout << "\nMaking histogram for simulated data in " << simDataFilesVec[D] 
        << endl;
// start by making the histograms that are the starting points for our chains
    // Gelman and Carlin [1996] recommend ten or more chains if the target
    // distribution is unimodal (Martinez and Martinze, 2000, p. 453)
    // the starting points are chosen to be widely dispersed
    bool successfulInsertionFirst, successfulInsertionSecond, 
      successfulInsertionThird;
    bool successfulPQSplitSecond;

    //pointers to Adaptivehistogram objects as starting conditions
    AdaptiveHistogram* myHistFirst;
    AdaptiveHistogram* myHistSecond;

    if (dataDim == 1) {
      //histogram 1
      myHistFirst = new AdaptiveHistogram(pavingBox);
      // put in the data in a 'pulse' with no splitting, ie into root box
      successfulInsertionFirst = myHistFirst->insertFromRSSample(labData, NOLOG
      , 1);
      
      //histogram 2
      myHistSecond = new AdaptiveHistogram(pavingBox);
      // the same data into the second histogram
      successfulInsertionSecond = myHistSecond->insertFromRSSample(labData, 
      NOLOG, 1);
      successfulPQSplitSecond = false;
      if (successfulInsertionSecond) {
        // set up function objects for a priority split
        CompCount compCount;
        // split until number of leaves is >= minLeaves
        size_t minLeaves = 10;
        //size_t minLeaves = (labData.Samples.size()/50); // 20 when n = 1000
        CritLeaves_GTE critLeavesGTE(minLeaves);
        size_t minPQPoints = 1; // minimum of one data point in each box
        // do the priority split
        successfulPQSplitSecond = myHistSecond->prioritySplit(compCount,
             critLeavesGTE, NOLOG, minPQPoints); // no logging
      }
      
    } //end of making starting conditions for dataDim = 1
    
    else { // at current i do not have a point-mass filter set up for data with
       > 1. 
         // But should bring in Jenny's code for filtering.
      //histogram 1
      myHistFirst = new AdaptiveHistogram(pavingBox);
      // put in the data in a 'pulse' with no splitting, ie into root box
      successfulInsertionFirst = myHistFirst->insertFromRVec((*unlabDataIt), 
      NOLOG);
      
      //histogram 2
      myHistSecond = new AdaptiveHistogram(pavingBox);
      // the same data into the second histogram
      successfulInsertionSecond = myHistSecond->insertFromRVec((*unlabDataIt), 
      NOLOG);
      successfulPQSplitSecond = false;
      if (successfulInsertionSecond) {
        // set up function objects for a priority split
        CompCount compCount;
        // split until number of leaves is >= minLeaves
        //size_t minLeaves = 50;
        size_t minLeaves = ((*unlabDataIt).size()/50); // 20 when n = 1000
        CritLeaves_GTE critLeavesGTE(minLeaves);
        size_t minPQPoints = 1; // minimum of one data point in each box
        // do the priority split
        successfulPQSplitSecond = myHistSecond->prioritySplit(compCount,
             critLeavesGTE, NOLOG, minPQPoints); // no logging
      }
    } // end of making histograms for dataDim > 1

    #ifdef FORCEFAILINSERTION
      // debugging - force a failure here to check what program does
      successfulInsertionThird = false;
    #endif

    // set up for MCMC
    // our return object, if all goes well
    AdaptiveHistogramCollator* myCollPtr;
    myCollPtr = new AdaptiveHistogramCollator; 
  
    //set up for output
    // use the cxsc manipulators for changing printing of cxsc::reals to
       console
    int prec = 15;
    cout << cxsc::SaveOpt;
    cout << cxsc::Variable;
    cout << cxsc::SetPrecision(prec+2, prec);
  
    if (successfulInsertionFirst && successfulPQSplitSecond) {
      // containers for adaptive histograms
      // the starting points of the chains
      vector< AdaptiveHistogram* > hists;
      hists.push_back(myHistFirst);
      hists.push_back(myHistSecond);
      

      // how many chains are to be run = number starting histograms
      size_t chains = hists.size(); 
    
      if (chains < 2) {
        throw HistException("Chains < 2");
      }

    // set up proposal distribution object
    UniformProposal proposal;
    // set up prior distribution object
    LogCatalanPrior logPrior;

    size_t minPoints = 0;
    
    LOGGING_LEVEL logging = LOGSAMPLES; // leave it like this!
    LOGGING_LEVEL loggingInChangeStates = NOLOG;

    gsl_rng * rgsl = NULL;

    // should check that each hist to be done has a paving

    // set up a random number generator for uniform rvs
    const gsl_rng_type * tgsl;
    // set the library variables *gsl_rng_default and
    // gsl_rng_default_seed to default environmental vars
    gsl_rng_env_setup();
    tgsl = gsl_rng_default; // make tgsl the default type
    rgsl = gsl_rng_alloc (tgsl); // set up with default seed
    
    // set a seed for the data
    int mcmcSeed = 1234;
    gsl_rng_set(rgsl, mcmcSeed); // change the seed to our seed

    // set up containers for the stuff we need pass to the MCMC engine
    vector<SPSnodeList> nodeLists(chains);
    Size_tVec numLeavesVec(chains);
    Size_tVec numCherriesVec(chains);

    vector<string> sequenceStateFilenames(chains);
    vector<string> sequenceAverageFilenames(chains);
    vector<string> sequenceCollationFilenames(chains);
    vector<string> sequenceDiffsToAverageFilenames(chains);
    
    std::string baseSequenceStateFilename = dirName;
    baseSequenceStateFilename += "SequenceStates";
    std::string baseSequenceStateCollationFilename = dirName;
    baseSequenceStateCollationFilename += "SequenceStateCollations";
    std::string baseSequenceStateAverageFilename = dirName;
    baseSequenceStateAverageFilename += "SequenceStateAverages";
    std::string baseSequenceStateDiffsToAverageFilename = dirName;
    baseSequenceStateDiffsToAverageFilename +=  "SequenceStateDiffsToAverage";
    
    // files for outputing samples
    std::string samplesCollFilename = dirName;
    samplesCollFilename += "CollatedSamplesFromMCMCGRAuto.txt";
    std::string samplesLogFilename = dirName;
    samplesLogFilename += "LogSamplesFromMCMCGRAuto.txt";
    outputFileStart(samplesCollFilename);
    
    // names for leaves related stuff
    vector<string> leavesColNames(chains);
    vector<string> leavesRunningSumColNames(chains);
    vector<string> leavesSampleVarianceColNames(chains);
    std::string  baseLeavesColName = dirName;
    baseLeavesColName += "leaves_";
    std::string  baseLeavesRunningSumColName = dirName;
    baseLeavesRunningSumColName += "leavesSum_";
    std::string  baseLeavesSampleVarianceColName = dirName;
    baseLeavesSampleVarianceColName += "leavesVar_";
    std::string overallLeavesRunningSumColName = dirName;
    overallLeavesRunningSumColName += "OverallLeavesSum";
    
    // names for L1 related stuff
    vector<string> L1ColNames(chains);
    vector<string> L1RunningSumColNames(chains);
    vector<string> L1SampleVarianceColNames(chains);
    std::string baseL1ColName = dirName;
    baseL1ColName += "L1_";
    std::string baseL1RunningSumColName = dirName;
    baseL1RunningSumColName += "L1Sum_";
    std::string baseL1SampleVarianceColName = dirName;
    baseL1SampleVarianceColName += "L1Var_";
    std::string overallL1RunningSumColName = dirName;
    overallL1RunningSumColName += "OverallL1Sum";
    
    
    // should realy check on LOGSAMPLESANDGRAPH as well here
    // but at the moment I have not done anything about graphing
    if (logging = LOGSAMPLES) {
      outputFileStart(samplesLogFilename);
    }
    
    //std::string overSequenceAvgCollFilename =
       "CollationsOfAveragesOverSequences.txt";
    //outputFileStart(overSequenceAvgCollFilename);
    
    // a name for the file of diagnostics  for leaves
    std::string GRLeavesFilename = dirName;
    GRLeavesFilename += "GelmanRubinLeavesScalar.txt";
    //outputFileStart(GRL1Filename);
    
    // a name for a file of the leaves v_ij scalars
    std::string GR_vij_as_Leaves_Filename  = dirName;
    GR_vij_as_Leaves_Filename += "LeavesScalar.txt";
    
    // a name for the file of working calculations for the leaves scalar
       diagnostics 
    std::string GRLeavesWorkingCalcsFilename = dirName;
    GRLeavesWorkingCalcsFilename += "GelmanRubinLeavesScalarWorkingCalcs.txt";
    //outputFileStart(GRL1WorkingCalcsFilename);
    
    // a name for the file of diagnostics  for L1
    std::string GRL1Filename = dirName;
    GRL1Filename += "GelmanRubinL1Scalar.txt";
    //outputFileStart(GRL1Filename);
    
    // addition to output the L1 distances (v_ij's)
    // a name for a file of the L1 v_ij scalars
    std::string GR_vij_as_L1_Filename  =  dirName;
    GR_vij_as_L1_Filename += "L1Scalar.txt";
    
    // a name for the file of working calculations for the L1 scalar
       diagnostics 
    std::string GRL1WorkingCalcsFilename = dirName;
    GRL1WorkingCalcsFilename += "GelmanRubinL1ScalarWorkingCalcs.txt";
    //outputFileStart(GRL1WorkingCalcsFilename);
    
    
    
    /* containers for summaries for the 
    * Leaves-distances-to-average scalar convergence diagnostics */
    
    /* note we don't need this for leaves */
    //std::vector < RealVec > currentLeaves(chains); 

    // one vector of leaves as a RealVec for each chain
    std::vector < RealVec >* leavesPtr = new std::vector < RealVec >(chains);  

    /* vector containing one running sum of leaves for each chain
    we can work out the average v = leaves for each chain so far from this
    start with a running sum of 0.0 for each chain */
    RealVec* runningSumLeavesPtr = new RealVec (chains, cxsc::real(0.0));
    
    /* vector containing one running sum of 
    squared leaves for each chain
    we can work out the average of the squared v's ie v^2 = leaves^2
    for each chain so far from this
    start with a running sum of 0.0 for each chain.
    (Use a dotprecision for each running sum to keep accuracy 
    when accumulating products of reals) */
    VecDotPrec runningSumLeavesSquared(chains, cxsc::dotprecision(0.0));

    /* value of running sum of leaves over all chains
    we can work out the average v = leaves over all chains so far from this */
    real runningSumLeavesAllChains = cxsc::real(0.0);
    
    #ifdef MYDEBUG
      // keep a vector of all the overall running sums as well
      RealVec* runningSumLeavesOverallPtr = new RealVec();
      // keep a vector of the runningsums for each chain as well
      std::vector < RealVec >* runningSumLeavesChainsPtr 
                = new std::vector < RealVec >(chains);
      // keep a vector of the sample variances for each chain as well
      std::vector < RealVec >* sampleVariancesLeavesPtr 
                = new std::vector < RealVec >(chains,
                  RealVec(1, cxsc::real(0.0)) );
      /* keep a vector of the flag for leaves convergence
       * (it's not a real, but easier to output it if we treat it like one) */
      RealVec* rhatLeavesFlagPtr = new RealVec(1, cxsc::real(0.0));
      
    #endif

    RealVec* Ws_leavesPtr = new RealVec(1, cxsc::real (0.0) ); // to hold the
       Ws_leaves
    RealVec* Bs_leavesPtr = new RealVec(1, cxsc::real (0.0) ); // to hold the
       Bs_leaves
    RealVec* estVarV_leavesPtr = new RealVec(1, cxsc::real (0.0) ); // to hold
       the estimated var(v) for leaves
    RealVec* rhat_leavesPtr = new RealVec(1, cxsc::real (0.0) ); // to hold the
       rhats for leaves

    
    // ------------------------------------
    
    
    /* ------------------------------------
     * containers for summaries for the 
    * L1-distances-to-average scalar convergence diagnostics */
    
    /* for each chain we need a container for current L1-distances-to-average 
     * relative to the current average for all histogram states in the chain so
       far.
     * This is reused and overwritten each time a state is added to the chain
     * and is just a working-space to facilitate getting the L1s we want. */
    std::vector < RealVec > currentL1s(chains); 

    // one vector of L1-distances-to-average as a RealVec for each chain
    std::vector < RealVec >* distancesL1Ptr = new std::vector < RealVec >(
      chains);  

    /* vector containing one running sum of L1-distances-to-average for each
       chain
    we can work out the average v = L1 for each chain so far from this
    start with a running sum of 0.0 for each chain */
    RealVec* runningSumL1Ptr = new RealVec (chains, cxsc::real(0.0));
    
    /* vector containing one running sum of 
    squared-L1-distances-to-average for each chain
    we can work out the average of the squared v's ie v^2 = L1^2
    for each chain so far from this
    start with a running sum of 0.0 for each chain.
    (Use a dotprecision for each running sum to keep accuracy 
    when accumulating products of reals) */
    VecDotPrec runningSumL1Squared(chains, cxsc::dotprecision(0.0));

    /* value of running sum of L1-distances-to-average over all chains
    we can work out the average v = L1 over all chains so far from this */
    real runningSumL1AllChains = cxsc::real(0.0);
    
    #ifdef MYDEBUG
      // keep a vector of all the overall running sums as well
      RealVec* runningSumL1OverallPtr = new RealVec();
      // keep a vector of the runningsums for each chain as well
      std::vector < RealVec >* runningSumL1ChainsPtr 
                = new std::vector < RealVec >(chains);
      // keep a vector of the sample variances for each chain as well
      std::vector < RealVec >* sampleVariancesL1Ptr 
                = new std::vector < RealVec >(chains,
                  RealVec(1, cxsc::real(0.0)) );
      /* keep a vector of the flag for L1 convergence
       * (it's not a real, but easier to output it if we treat it like one) */
      RealVec* rhatL1FlagPtr = new RealVec(1, cxsc::real(0.0));
    #endif  
    
    RealVec* Ws_L1Ptr = new RealVec(1, cxsc::real (0.0) ); // to hold the Ws_L1
    RealVec* Bs_L1Ptr = new RealVec(1, cxsc::real (0.0) ); // to hold the Bs_L1
    RealVec* estVarV_L1Ptr = new RealVec(1, cxsc::real (0.0) ); // to hold the
       estimated var(v) for L1
    RealVec* rhat_L1Ptr = new RealVec(1, cxsc::real (0.0) ); // to hold the
       rhats for L1
    
    // ------------------------------------

    #ifdef MYDEBUG
      /* keep a vector of indicators for whether a state was sampled
       * (not a real, but easier to output it if we treat it like one) */
      RealVec* sampledIndPtr = new RealVec(1, cxsc::real(0.0));
    #endif


    // container of each state at each sequence
    vector<AdaptiveHistogramCollator*> sequenceCollators;

    //container for the collation of the averages over each sequence at each
       state
    //vector<AdaptiveHistogramCollator*> averageCollators;

    //AdaptiveHistogramCollator masterCollator; // not newed so no need to
       delete

    bool cancontinue = true;

    /* need to accumulate sum over all chains of the square of 
     * the running sum of leaves 
     * for each chain for this starting state */
    cxsc::real initialSumOfSquaresOfRunningSumsLeaves(0.0);
    
    // this loop is just setting up containers of file names
    // and getting info from the starting histograms that is
    // needed to start the chains
    for (size_t ci = 0; ci < chains; ci++) {
      
      // do not comment these out
      std::ostringstream stm1;
      stm1 << baseSequenceStateFilename << ci << ".txt";
      sequenceStateFilenames[ci] = stm1.str();
      outputFileStart(sequenceStateFilenames[ci]);
      
      // addition to output the L1 distances (v_ij's)
      // moved this code out of the ifdef MYDEBUG section below
      {
        std::ostringstream stm;
        stm << baseL1ColName << ci;
        L1ColNames[ci] = stm.str();
      }
      
      {
        std::ostringstream stm;
        stm << baseLeavesColName << ci;
        leavesColNames[ci] = stm.str();
      }

      #ifdef MYDEBUG
        {
          std::ostringstream stm;
          stm << baseSequenceStateCollationFilename << ci << ".txt";
          sequenceCollationFilenames[ci] = stm.str();
          outputFileStart(sequenceCollationFilenames[ci]);
        }
        {
          std::ostringstream stm;
          stm << baseSequenceStateAverageFilename << ci << ".txt";
          sequenceAverageFilenames[ci] = stm.str();
          outputFileStart(sequenceAverageFilenames[ci]);
        }
        {
          std::ostringstream stm;
          stm << baseSequenceStateDiffsToAverageFilename << ci << ".txt";
          sequenceDiffsToAverageFilenames[ci] = stm.str();
          outputFileStart(sequenceDiffsToAverageFilenames[ci]);
        }
        
        // leaves
        {
          std::ostringstream stm;
          stm << baseLeavesRunningSumColName << ci;
          leavesRunningSumColNames[ci] = stm.str();
        }
        
        {
          std::ostringstream stm;
          stm << baseLeavesSampleVarianceColName << ci;
          leavesSampleVarianceColNames[ci] = stm.str();
        }
        
        // L1 distances
        {
          std::ostringstream stm;
          stm << baseL1RunningSumColName << ci;
          L1RunningSumColNames[ci] = stm.str();
        }
        
        {
          std::ostringstream stm;
          stm << baseL1SampleVarianceColName << ci;
          L1SampleVarianceColNames[ci] = stm.str();
        }
      #endif
      /* we only need to do this because we are doing a step-by-step change of
       the
      * histogram states 'from the outside', ie through this example:  we need
       to
      * collect the stuff the histogram's changeMCMCstate method needs to make
       one 
      * change.  */
      
      // set up a container for the leaf children
      SPSnodePtrs leafVec;
      // set up a container for the subleaf children
      SPSnodePtrs cherryVec;

      size_t numLeaves = 0;
      size_t numCherries = 0;

      // fill the container with the leaf children
      hists[ci]->getSubPaving()->getLeaves(leafVec);
      // fill the container with the subleaf children
      hists[ci]->getSubPaving()->getSubLeaves(cherryVec);

      numCherries = cherryVec.size();

      // check if node is still splittable
      if (!leafVec.empty()) {
         // but only put into the container the leaves which, if split,
         // would have at least minPoints data points associated with them
         SPSnodePtrsItr lit;
         for (lit = leafVec.begin(); lit < leafVec.end(); lit++) {
            if (((*lit)->getLeftCountIfSplit() >= minPoints) &&
              ((*lit)->getRightCountIfSplit() >= minPoints)) {
                 // leaf can go into container
                 nodeLists[ci].push_back(*lit);
                 numLeaves++;
            }
         }
      }

      // no need to check on cherries - they can all go in
      if (numCherries > 0)
         nodeLists[ci].insert(nodeLists[ci].end(), cherryVec.begin(),
                         cherryVec.end());
      if (nodeLists[ci].size() == 0) {
         cancontinue = false;
         break; // break out of the for loop
         std::cout << "No changeable nodes given minPoints = "
                 << minPoints << " in histogram " << ci
                 << ". Sorry, aborting MCMC." << std::endl;
      }

      numLeavesVec[ci] = numLeaves;
      numCherriesVec[ci] = numCherries;

      // note nothing in the sequence collators yet

      // initialise things for the collection of data on leaves
      
      // one vector of leaves for each chain
      // record leaves for this first state
      cxsc::real lastStateLeaves(1.0*hists[ci]->getRootLeaves());
      leavesPtr->at(ci).push_back( lastStateLeaves );  
      
      // update the running sum of leaves for the chain, held in
       runningSumLeaves
      cxsc::real newRunningSumLeaves = runningSumLeavesPtr->at(ci) + 
      lastStateLeaves;
      runningSumLeavesPtr->at(ci) = newRunningSumLeaves;
          
      // accumulate the square of the running sum of leaves 
      initialSumOfSquaresOfRunningSumsLeaves += newRunningSumLeaves*
      newRunningSumLeaves;
          
      /* update the running sum of squared leaves over this chain
       *  held in runningSumLeavesSquared as a dot precision */
      cxsc::accumulate( runningSumLeavesSquared[ci], lastStateLeaves, 
      lastStateLeaves );
      
      // update  the overall running sum runningSumLeavesAllChains 
      runningSumLeavesAllChains += lastStateLeaves;
      
      #ifdef MYDEBUG
        //sampleVariancesLeavesPtr->at(ci) was initialised to 0.0
        runningSumLeavesChainsPtr->at(ci).push_back (newRunningSumLeaves);
      #endif
      
      
    } // end loop through chains setting up things to be able to start
    
    #ifdef MYDEBUG
      // store the current runningSumLeavesAllChains as well
      runningSumLeavesOverallPtr->push_back(runningSumLeavesAllChains);
    #endif    
    
    /* the overall running sum runningSumLeavesAllChains 
     * was initialised to 0.0 
     * and #ifdef MYDEBUG, runningSumLeavesOverall was initialised to contain
       one 0.0 
     * and similarly rhatLeavesFlagPtr was initialised to contain one 0.0*/
    
    
    /* and we started the convergence statistics for chains with just one state
       in
     * with one 0.0 in each (Ws, Bs, estVarsVs, rhats)
     * when we initialised */
    
    bool goodLoop = cancontinue;
    
    if (cancontinue) cout << "About to do MCMC" << endl;

    /* set up some variables we need to keep track of states and sampling */
    
    int samplesSoFar = 0;
    
    size_t states = 1;  /* keep track of states in the chain = 1 so far,
              since state 1 is the initial histograms */
    
    /* varibles for monitoring convergence
     * we only have one scalar value at the moment (L1-distance-to-average) but
     * we might have more - might want convergence on all diagnostics */
    int rhatFlagCounter = 0;
    int rhatL1Flag = 0; // indicator for whether we are burntin on L1 scalar
       value
    int rhatLeavesFlag = 0; // indicator for whether we are burntin on L1
       scalar value

    /* indicator for whether we have passed the first hurdle
    (the leaves convergence) and are now monitoring for 
    actual burnin (note that the input parameter 
    startWithFullChecks = 1 will effectively override the need to pass the
    first hurdle*/
    
    int doFullChecks = startWithFullChecks; 
    
    size_t startFullChecks = 0; // record the point where 
                // we could start the full diagnostics checks
    
    int burntin = 0; // indicator for whether we consider ourselves burntin yet
    
    size_t burntinReachedState = 0; // keep track of when we (last) reached
       burnin
    
    // counter to keep track of loops
    int loopCounter = 0;
    
    /* We also need a collator for the samples*/
    AdaptiveHistogramCollator* samplesColl = new AdaptiveHistogramCollator();
    
    while (goodLoop && (loopCounter < maxLoops) && (samplesSoFar < 
      samplesNeeded)) {
      
      #ifdef MYDEBUG_CALCS
        cout << "****** Change from state number " << states << " ******" << 
      endl;
      #endif
      
      loopCounter++;
      
      /* if we want to do full checks, 
       * but have not yet got the sequence collators
       * then we need to initialise before we change state */
      if (doFullChecks && sequenceCollators.empty()) {
    
        // record when we started the full checks
        startFullChecks = states;
        
        #ifdef MYDEBUG
          cout << "\nStarted full checks at state " << startFullChecks << "\n" 
      << endl;
        #endif
        
        // initialise things using current histogram state
        for (size_t ci = 0; ci < chains; ++ci) {
          
          /* set up one collator for each chain, 
           * starting it with the histogram state right now */
          sequenceCollators.push_back( new AdaptiveHistogramCollator( *hists[ci
      ] ) );
          
          // collect the calculations for the starting points - L1 distances
    
          // diff to average will be 0.0 since there is only one state in the
       collator
          distancesL1Ptr->at(ci).push_back( cxsc::real(0.0) ); 
          
          #ifdef MYDEBUG
            runningSumL1ChainsPtr->at(ci).push_back( cxsc::real(0.0) );
          #endif
          
          /* #ifdef MYDEBUG, sampleVariancesL1Ptr vectors for each chain 
           * started with one 0.0 in 
           *
           * running sum of L1s for each chain, held in runningSumL1Ptr
          are all initialised to 0.0 already 
          * 
          * running sum of squared L1s for each chain, held in 
       runningSumL1SquaredPtr
          are all initialised to 0.0 already
          */ 
          
          
          #ifdef MYDEBUG_OUTPUT
          {
            sequenceCollators[ci]->publicOutputLog(sequenceCollationFilenames[
      ci], 1);
        
            AdaptiveHistogramCollator colltempavg
                        = sequenceCollators[ci]->makeAverage();
            colltempavg.publicOutputLog(sequenceAverageFilenames[ci], 1);
            
            AdaptiveHistogramCollator colltempdiffs
                        = sequenceCollators[ci]->makeDifferencesToAverage();
            colltempdiffs.publicOutputLog(sequenceDiffsToAverageFilenames[ci], 
      1);
          } // temp objects go out of scope here  
          #endif
          
        }
        
        // do initial values for everything so far
        
         #ifdef MYDEBUG
          runningSumL1OverallPtr->push_back( cxsc::real(0.0) );
        #endif
        
        /* the overall running sum runningSumL1AllChains 
         * was initialised to 0.0 
         * and #ifdef MYDEBUG, rhatL1FlagPtr was initialised to contain one 0.0
         * and sampledIndPtre was initialised to contain one 0.0*/

        /* and we started the convergence statistics for chains with just one
       state in
         * with one 0.0 in each (Ws, Bs, estVarsVs, rhats)
         * when we initialised */
        
      }

      
      /* we want to accumulate the sample variance of the scalar summary leaves
       * for each chain up to the point reached in this loop */
      cxsc::real sumOfSampleVariancesLeavesOverChains(0.0);
      
      /* also accumulate sum over all chains of the square of 
       * the running sum of leaves 
       * for each chain up to the point reached in this loop */
      cxsc::real sumOfSquaresOfRunningSumsLeaves(0.0);
      
      /* we want to accumulate the sample variance of the scalar summary L1
       * for each chain up to the point reached in this loop */
      cxsc::real sumOfSampleVariancesL1OverChains(0.0);
      
      /* also accumulate sum over all chains of the square of 
       * the running sum of L1-distances-to-average 
       * for each chain up to the point reached in this loop */
      cxsc::real sumOfSquaresOfRunningSumsL1(0.0);
      
      // for each histogram in turn, change the state
      /* 
       * this is all a fudge - changeMCMCstate should just be a private
       * method of the histograms but I think I made it public so that
       * I could use it here in the example as a first step to being
       * able to make all of this chain convergence stuff back into
       * a method of the histograms themselves
       */
      for (size_t ci = 0; ci < chains; ci++) {
        
        #ifdef MYDEBUG_CALCS
          cout << "--- chain index " << ci << " ---" << endl;
        #endif
        
        /* I refer to the current chain, indexed by ci, as 'the chain
         * in the comments inside this loop */

        // changeMCMCState for the chain
        // updates nodes, numLeaves, numCherries, i
        goodLoop = hists[ci]->changeMCMCState(nodeLists[ci],
               numLeavesVec[ci], numCherriesVec[ci],
               proposal, logPrior, minPoints,
               rgsl, loggingInChangeStates,
               sequenceStateFilenames[ci], states);
               
        #ifdef FORCEFAILMCMCLOOP
          // for debugging - force a loop failure and see what happens to
       program
          if (states == 5) goodLoop = false;
        #endif 

        if (!goodLoop) {
          throw std::runtime_error("Failed to do MCMC change in state");
          // stop if we aren't happy
        }
        
        if ((numLeavesVec[ci] == 0 && numCherriesVec[ci] == 0)) {
          throw std::runtime_error("No more leaves or cherries in MCMC");
        }
        
        // so assume all is okay if we have not just thrown an exception
        
        /* this chain should have states + 1 states in it
         * because we have not yet incremented the states variable.*/
        size_t n_for_leaves = states + 1;
                
        /* and n_Leaves should be at least 2 because we started with the 
         * starting histogram and have now added another state.*/
        assert(n_for_leaves > 1);
        
        // collect the leaves scalar and update the running sums for leaves
        {
          // update leaves for last histogram state in the chain
          cxsc::real lastStateLeaves(1.0*hists[ci]->getRootLeaves());
          leavesPtr->at(ci).push_back( lastStateLeaves );  
                  
          // update the running sum of leaves for the chain, held in
       runningSumLeaves
          cxsc::real newRunningSumLeaves = runningSumLeavesPtr->at(ci) + 
      lastStateLeaves;
          runningSumLeavesPtr->at(ci) = newRunningSumLeaves;
          
          // accumulate the square of the running sum of leaves 
          sumOfSquaresOfRunningSumsLeaves += newRunningSumLeaves*
      newRunningSumLeaves;
          
          /* update the running sum of squared leaves over this chain
           *  held in runningSumLeavesSquared as a dot precision */
          cxsc::accumulate( runningSumLeavesSquared[ci], lastStateLeaves, 
      lastStateLeaves );
          
          // update  the overall running sum runningSumLeavesAllChains 
          runningSumLeavesAllChains += lastStateLeaves;
          
          /* accumulate the sample variance for leaves for this chain: 
           * sample variance for the scalar summary v = leaves
           * calculated as (sum of squares - n * square of averages)/(n-1)
           * which equals (sum of squares - square of sums/n)/(n-1) */
          cxsc::real thisSampleVarianceLeaves( ( 1.0/(n_for_leaves - 1) )
              *( cxsc::rnd(runningSumLeavesSquared[ci])
              -  (newRunningSumLeaves*newRunningSumLeaves/(n_for_leaves * 1.0))
       ) );
          sumOfSampleVariancesLeavesOverChains += thisSampleVarianceLeaves;
          
          #ifdef MYDEBUG
            sampleVariancesLeavesPtr->at(ci).push_back( 
      thisSampleVarianceLeaves );
            runningSumLeavesChainsPtr->at(ci).push_back (newRunningSumLeaves);
          #endif

          
          #ifdef MYDEBUG_CALCS
            //check thisSampleVariance is correct, doing it the long way
            // leavesPtr[ci] has the v_ij for each chain i
            
            assert( n_for_leaves == leavesPtr->at(ci).size() );
            cxsc::real acc(0.0);
            for (RealVecItr it = leavesPtr->at(ci).begin(); it < leavesPtr->at(
      ci).end(); ++it) {
              acc+= (*it);
            }
            
            cxsc::real av = acc/(n_for_leaves * 1.0);
            cxsc::dotprecision accDiffs(0.0);
            for (RealVecItr it = leavesPtr->at(ci).begin(); it < leavesPtr->at(
      ci).end(); ++it) {
              cxsc::real thisDiff = (*it) - av;
              // sum up the squares of the differences compared to overall
       average
              cxsc::accumulate(accDiffs, thisDiff, thisDiff);
            }
            cxsc::real altVar = rnd(accDiffs)/( n_for_leaves - 1.0 );
            
            cout << "\nthisSampleVariance leaves is\t" << 
      thisSampleVarianceLeaves << endl;
            cout << "altSampleVar leaves is\t" << altVar << endl;
            //assert(cxsc::_double(thisSampleVarianceLeaves) ==
       cxsc::_double(altVar) );
          
          #endif
        } 
        
        /* if we are doing the full checks
         *  collect the L1 distances and update the runnings sums */
        if (doFullChecks) {
          
          sequenceCollators[ci]->addToCollation(*(hists[ci]));
          
          /* how many histograms have we got so far?
           * this chain should have states - startFullChecks + 2 states in it,
           * because we only started fullChecks at startFullChecks
           * and we have not yet incremented the states counter.*/
          size_t n_for_L1 = sequenceCollators[ci]->getNumberCollated();
          assert(n_for_L1 == states - startFullChecks + 2);
                  
          /* and n_for_L1 should be at least 2*/
          assert(n_for_L1 > 1);
          
          // update our collection of L1s to average for all histogram states
       in the chain
          currentL1s[ci] = sequenceCollators[ci]->getL1DistancesToAverage(
      currentL1s[ci]);
          /* we actually only want the L1 for the last state in the chain,
           * which we collect in the right vector for this chain in distancesL1
       */
          cxsc::real lastStateL1 = currentL1s[ci].back();
          distancesL1Ptr->at(ci).push_back( lastStateL1 );  
                  
          // update the running sum of L1s for the chain, held in runningSumL1
          cxsc::real newRunningSumL1 = runningSumL1Ptr->at(ci) + lastStateL1;
          runningSumL1Ptr->at(ci) = newRunningSumL1;
          
          // accumulate the square of the running sum of L1s 
          sumOfSquaresOfRunningSumsL1 += newRunningSumL1*newRunningSumL1;
          
          /* update the running sum of squared L1s over this chain
           *  held in runningSumL1Squared as a dot precision */
          cxsc::accumulate( runningSumL1Squared[ci], lastStateL1, lastStateL1 )
      ;
          
          // update  the overall running sum runningSumL1AllChains 
          runningSumL1AllChains += lastStateL1;
          
          /* accumulate the sample variance for L1 for this chain: 
           * sample variance for the scalar summary v = L1-to-average
           * calculated as (sum of squares - n * square of averages)/(n-1)
           * which equals (sum of squares - square of sums/n)/(n-1) */
          cxsc::real thisSampleVarianceL1( ( 1.0/(n_for_L1-1) )*( cxsc::rnd(
      runningSumL1Squared[ci])
                    -  (newRunningSumL1*newRunningSumL1/(n_for_L1 * 1.0)) ) );
          sumOfSampleVariancesL1OverChains += thisSampleVarianceL1;
          
          #ifdef MYDEBUG
            sampleVariancesL1Ptr->at(ci).push_back( thisSampleVarianceL1 );
            runningSumL1ChainsPtr->at(ci).push_back (newRunningSumL1);
          #endif

          
          #ifdef MYDEBUG_CALCS
            //check thisSampleVariance is correct, doing it the long way
            // distancesL1Ptr[ci] has the v_ij for each chain i
            assert( n_for_L1 == distancesL1Ptr->at(ci).size() );
            cxsc::real acc(0.0);
            for (RealVecItr it = distancesL1Ptr->at(ci).begin(); 
              it < distancesL1Ptr->at(ci).end(); ++it) {
              acc+= (*it);
            }
            cxsc::real av = acc/(n_for_L1 * 1.0);
            cxsc::dotprecision accDiffs(0.0);
            for (RealVecItr it = distancesL1Ptr->at(ci).begin(); 
              it < distancesL1Ptr->at(ci).end(); ++it) {
              cxsc::real thisDiff = (*it) - av;
              // sum up the squares of the differences compared to overall
       average
              cxsc::accumulate(accDiffs, thisDiff, thisDiff);
            }
            cxsc::real altVar = rnd(accDiffs)/( n_for_L1 - 1.0 );
            
            cout << "\nthisSampleVarianceL1 is\t" << thisSampleVarianceL1 << 
      endl;
            cout << "altSampleVarL1 is\t" << altVar << endl;
            //assert(cxsc::_double(thisSampleVarianceL1) ==
       cxsc::_double(altVar) );
          
          #endif
          
          #ifdef MYDEBUG_OUTPUT
            // make files for current average and current collations
            sequenceCollators[ci]->publicOutputLog(sequenceCollationFilenames[
      ci], n_for_L1);
          
            AdaptiveHistogramCollator colltempavg
                        = sequenceCollators[ci]->makeAverage();
            colltempavg.publicOutputLog(sequenceAverageFilenames[ci], n_for_L1)
      ;
            
            AdaptiveHistogramCollator colltempdiffs
                        = sequenceCollators[ci]->makeDifferencesToAverage();
            colltempdiffs.publicOutputLog(sequenceDiffsToAverageFilenames[ci], 
      n_for_L1);
          #endif
        }
          
      } // end change state for each histogram in turn
      
      // increment number of states histograms have been through  
      states++;
        

      /* each chain now has a new state
       * and info for leaves scalar for diagnostics has been collected
       * and the sample variance of the leaves scalar for each chain 
       * has been put into sampleVariancesLeaves vector,
       * so we can now work out whether the initial hurdle has been passed
       * 
       * and if we are doing full checks, the current histogram states have 
       * has been collated into collators 
       * and info for any other scalars for diagnostics has been collected
       * and the sample variance of these other scalar summaries for each chain
       
       * for each scalar value
       * have been put into sampleVariances vectors for each diagnostic,
       * so we can now work out the convergence diagnostics */

      #ifdef MYDEBUG
        // store the current runningSumLeavesAllChains as well
        runningSumLeavesOverallPtr->push_back(runningSumLeavesAllChains);
        
        if (doFullChecks) {
          // store the current runningSumL1AllChains as well
          runningSumL1OverallPtr->push_back(runningSumL1AllChains);
        }
        
      #endif
      
      // convergence diagnostics calculations for leaves
      {
        // the Ws_leaves: average, over chains, of sample variance of scalar
       value
        cxsc::real thisW_leaves = sumOfSampleVariancesLeavesOverChains/(chains 
      * 1.0); 
        Ws_leavesPtr->push_back(thisW_leaves); 
        // the Bs_leaves
        cxsc::real thisB_leaves = (1.0/( (chains - 1) * states ) 
                  * ( sumOfSquaresOfRunningSumsLeaves 
                  - (runningSumLeavesAllChains 
                  * runningSumLeavesAllChains/(chains * 1.0)) ) );
        Bs_leavesPtr->push_back(thisB_leaves); 
        
        #ifdef MYDEBUG_CALCS
          //check thisB_leaves is correct, doing it the long way
          // runningSumLeaves has one running sum for each chain
          RealVec chainAverages;
          cxsc::real accRunningSums(0.0);
          for (RealVecItr it = runningSumLeavesPtr->begin(); it < 
      runningSumLeavesPtr->end(); ++it) {
            cxsc::real thisChainRunningSum = (*it);
            cxsc::real thisChainAv = thisChainRunningSum/(states * 1.0);
            chainAverages.push_back(thisChainAv);
            accRunningSums+=thisChainRunningSum;
          }
          cxsc::real overallAv = accRunningSums/(states * chains * 1.0);
          cxsc::dotprecision accDiffs(0.0);
          for (RealVecItr it = chainAverages.begin(); it < chainAverages.end();
       ++it) {
            cxsc::real thisDiff = (*it) - overallAv;
            // sum up the squares of the differences compared to overall
       average
            cxsc::accumulate(accDiffs, thisDiff, thisDiff);
          }
          cxsc::real altB = rnd(accDiffs)*( states/(chains - 1.0) );
          
          cout << "\nthisB for leaves is\t" << thisB_leaves << endl;
          cout << "altB for leaves is\t" << altB << endl;
          //assert(thisB_leaves == altB);
        
        #endif
        
        // the estimated var(v)
        cxsc::real thisVarV_leaves = states/(states-1.0) 
                * thisW_leaves + (1.0/states)*thisB_leaves;
        estVarV_leavesPtr->push_back(thisVarV_leaves); 
        // the rhats
        cxsc::real thisRhat_leaves(0.0);
        // allow division by 0 if w = 0 when var does not
        if (thisW_leaves > 0.0 || thisVarV_leaves > 0.0) {
          thisRhat_leaves = thisVarV_leaves/thisW_leaves;
        }
        rhat_leavesPtr->push_back(thisRhat_leaves); 
        
      } // end calculations for leaves
      
      
      // check on the diagnostics for Leaves
      if (rhat_leavesPtr->back() <= 1.0 + tol_leaves 
              && rhat_leavesPtr->back() >= 1.0 - tol_leaves) {
        
        // if we have not been converged before on this scalar value
        if (!rhatLeavesFlag)  {
          #ifdef MYDEBUG
            
            cout << "\nleaves convergence test satisfied in state " 
                << states << endl;
            
          #endif
        
          // set the flag for this scalar value
          rhatLeavesFlag = 1;
          
          // and increment the flag counter = we are converged on this scalar
       value
          rhatFlagCounter ++; 
          
          if (!doFullChecks) doFullChecks = 1;
        }
      }
      else { // not converged on this scalar value
        
        // if we were okay on this scalar value before
        if (rhatLeavesFlag) {
          #ifdef MYDEBUG
            cout << "\nLeaves convergence test now NOT satisfied in state " 
              << states << endl;
        
          #endif
          rhatLeavesFlag = 0; // update the flag
          rhatFlagCounter--; // decrement the flag counter
        }
        
        /* note that we don't turn off the full checks even if
         * the leaves criteria ceases to be satisfied */    
      }
      
      #ifdef MYDEBUG
        // store the Leavesflag as well, as a real, which is a fudge...
        rhatLeavesFlagPtr->push_back(rhatLeavesFlag);
        
      #endif
      
      
      /* if we are doing the full checks, do the convergence diagnostics
       * for the other scalars*/
      if (doFullChecks && (!sequenceCollators.empty())) {
        
        // convergence diagnostics calculations for L1
      
        size_t n_for_L1 = states - startFullChecks + 1;
        assert(n_for_L1 == sequenceCollators.at(0)->getNumberCollated());
        
        assert( n_for_L1 > 1);
        
        // the Ws_L1: average, over chains, of sample variance of scalar value
        cxsc::real thisW_L1 = sumOfSampleVariancesL1OverChains/(chains * 1.0); 
        Ws_L1Ptr->push_back(thisW_L1); 
        // the Bs_L1
        cxsc::real thisB_L1 = (1.0/( (chains - 1) * n_for_L1 ) 
                  * ( sumOfSquaresOfRunningSumsL1 
                  - (runningSumL1AllChains 
                  * runningSumL1AllChains/(chains * 1.0)) ) );
        Bs_L1Ptr->push_back(thisB_L1); 
        
        #ifdef MYDEBUG_CALCS
          //check thisB_L1is correct, doing it the long way
          // runningSumL1 has one running sum for each chain
          RealVec chainAverages;
          cxsc::real accRunningSums(0.0);
          for (RealVecItr it = runningSumL1Ptr->begin(); it < runningSumL1Ptr->
      end(); ++it) {
            cxsc::real thisChainRunningSum = (*it);
            cxsc::real thisChainAv = thisChainRunningSum/(n_for_L1 * 1.0);
            chainAverages.push_back(thisChainAv);
            accRunningSums+=thisChainRunningSum;
          }
          cxsc::real overallAv = accRunningSums/(n_for_L1 * chains * 1.0);
          cxsc::dotprecision accDiffs(0.0);
          for (RealVecItr it = chainAverages.begin(); it < chainAverages.end();
       ++it) {
            cxsc::real thisDiff = (*it) - overallAv;
            // sum up the squares of the differences compared to overall
       average
            cxsc::accumulate(accDiffs, thisDiff, thisDiff);
          }
          cxsc::real altB = rnd(accDiffs)*( n_for_L1/(chains - 1.0) );
          
          cout << "\nthisB for L1is\t" << thisB_L1 << endl;
          cout << "altB for L1 is\t" << altB << endl;
          //assert(thisB_L1 == altB);
        
        #endif
        
        // the estimated var(v)
        cxsc::real thisVarV_L1 = n_for_L1/(n_for_L1-1.0) * thisW_L1 + (1.0/
      n_for_L1)*thisB_L1;
        estVarV_L1Ptr->push_back(thisVarV_L1); 
        // the rhats
        cxsc::real thisRhat_L1(0.0);
        // allow division by 0 if w = 0 when var does not
        if (thisW_L1 > 0.0 || thisVarV_L1 > 0.0) {
          thisRhat_L1 = thisVarV_L1/thisW_L1;
        }
        rhat_L1Ptr->push_back(thisRhat_L1); 
      } // end calculations for L1
      
      
      // check on the diagnostics for L1
      if (doFullChecks && (rhat_L1Ptr->back() <= 1.0 + tol_L1 
                  && rhat_L1Ptr->back() >= 1.0 - tol_L1) ) {
        
        // if we have not been converged before on this scalar value
        if (!rhatL1Flag)  {
          #ifdef MYDEBUG
            
            cout << "\nL1 convergence test satisfied at " 
                << states << endl;
            
          #endif
        
          // set the flag for this scalar value
          rhatL1Flag = 1;
          
          // and increment the flag counter = we are converged on this scalar
       value
          rhatFlagCounter ++; 
        }
      }
      else { // not converged on this scalar value
        
        // if we were okay on this scalar value before
        if (rhatL1Flag) {
          #ifdef MYDEBUG
            cout << "\nL1 convergence test NOT now satisfied at " 
              << states << endl;
        
          #endif
          rhatL1Flag = 0; // update the flag
          rhatFlagCounter--; // decrement the flag counter
        }     
      }
      
      #ifdef MYDEBUG
        if (doFullChecks && (!sequenceCollators.empty()) ) {
        
          // store the L1flag as well, as a real, which is a fudge...
          rhatL1FlagPtr->push_back(rhatL1Flag);
        }
      #endif
      
      /* we'd do this for all other scalar values as well, if applicable, then
       ...*/
        
      // check if we have enough flags to consider ourselves burntin
      if ( !burntin && (rhatFlagCounter >= rhatFlagCounterThreshold) ) {
        
        burntin = 1; 
        burntinReachedState = states;
        
        #ifdef MYDEBUG
          // if we have not been burntin, give a message
           cout << "Burnin convergence test satisfied at state " 
              << burntinReachedState << endl;
          
        #endif

      }
      
      // but it may be that we were burntin and no longer are
      else if ( burntin && (rhatFlagCounter < rhatFlagCounterThreshold) ) {
        
        burntin = 0; 
        burntinReachedState = 0;
        
        delete samplesColl; // get rid of the old samples collator
        samplesColl = new AdaptiveHistogramCollator(); // and take a new one
        
        samplesSoFar = 0;
        
        // want to change all the 1's in sampledIndPtr so far to 0s
        cxsc::real newVal(0.0);
        
        #ifdef MYDEBUG
          std::replace_if (sampledIndPtr->begin(), sampledIndPtr->end(), 
            std::bind2nd(greater< cxsc::real >(),newVal), newVal);
        #endif
        
        // restart the log file if we are logging
        // note nothing done here yet about logging graphs as well  
        if (logging = LOGSAMPLES) {
          outputFileStart(samplesLogFilename);
        }   
        
        #ifdef MYDEBUG
          cout << "Burnin convergence test now NOT satisfied at state " 
              << states << endl;
          
        #endif
      }
      
      /* take samples if we are burntin and this is a sampling point according
       to 
       * the thinout specified 
       * note - we will only be in the loop at all if we still need more
       samples*/
      if (burntin && (( states - burntinReachedState )%thinout == 0)) {
        
        #ifdef MYDEBUG
          cout << "sampling at state " << states << endl;
          sampledIndPtr->push_back (cxsc::real(1.0)); 

        #endif
        
        // take one sample from each chain until we have enough samples
        // and increment samplesSoFar for each one taken
        vector<AdaptiveHistogram*>::iterator ait;
        for (ait = hists.begin(); 
            (ait < hists.end() && samplesSoFar < samplesNeeded);
            ++ait) {
          
          samplesColl->addToCollation(**ait);
          
          samplesSoFar++;
          
          if (logging = LOGSAMPLES) {
            (*ait)->outputLogPlain(samplesLogFilename, samplesSoFar);
          }
          
        }
        
      } // finished taking samples for this loop
      else {
        #ifdef MYDEBUG
          
          sampledIndPtr->push_back (cxsc::real(0.0)); 
        #endif
      }
      
      assert(samplesColl->getNumberCollated() == samplesSoFar);
      
      
      // back into loop
      #if !defined(MYDEBUG_CALCS)
        #ifdef MYDEBUG
          // output a line every now and again so that we know it's still alive
          if (loopCounter%100 == 0) {
            cout << "\n...I'm still going: completed change in state number " <
      < states << " ...\n" << endl;
          }
        #endif
      #endif
      
      
    }    // finished while loop - either loop failed or reached maxLoops or
       have all our samples
    
    cancontinue = goodLoop;
    
    #ifdef MYDEBUG
      cout << "****** finished all loops, states counter is = " << states << "
       ******" << endl;
    #endif
    
    cout << "\nnumber of samples collected is = " << samplesColl->
      getNumberCollated() << endl;
    
    // free the random number generator
    gsl_rng_free (rgsl);

    cout << cxsc::RestoreOpt; // undo changes we made to cout printing for cxsc
       values
  
    
    /* is all okay with the loop
     * and we have all our samples */
    if (cancontinue && (samplesSoFar >= samplesNeeded) ) {  
      #ifdef MYDEBUG
        // output the overall collator
        samplesColl->outputToTxtTabs(samplesCollFilename);
      #endif
      
      // make the return object be the average of the samples
      *myCollPtr = samplesColl->makeAverage();
      
      // optional output for histogram
        string histFileName = dirName;
        histFileName += "AverageMCMC";
        histFileName += stmD.str();
        histFileName += ".txt";
        myCollPtr->outputAverageToTxtTabs(histFileName);
        // end of optional output for histogram
        
        //get estimated log-likelihood for observed data
        real estLogLik;
        if (dataDim == 1) {
          estLogLik=myCollPtr->getEstLogLikelihoodFromRSSample(
          labObsData, dx, wt, WeightHistVec[D], WeightPMVec[D]);
        }
        else {
          estLogLik=myCollPtr->getEstLogLikelihoodFromRSSample(
          labObsData, dx, wt);
        }
        cout << setprecision(16) <<"Estimated lik for Hist: " << estLogLik << 
      endl;
        logLikVec.push_back(estLogLik);
        
      // output the convergence diagnostics
      
      //output file for leaves
      {
        std::vector < std::string > colNames;
        colNames.push_back("W");
        colNames.push_back("B");
        colNames.push_back("estVarV");
        colNames.push_back("rhat");
        #ifdef MYDEBUG
          colNames.push_back("rhatFlag");
          colNames.push_back("sampled?");
        #endif
        std::vector < RealVec* > data;
        data.push_back(Ws_leavesPtr);
        data.push_back(Bs_leavesPtr);
        data.push_back(estVarV_leavesPtr);
        data.push_back(rhat_leavesPtr);
        #ifdef MYDEBUG
          data.push_back(rhatLeavesFlagPtr);
          data.push_back(sampledIndPtr);
        #endif
        int precData = 5;
        outputToFileVertical(data, colNames, GRLeavesFilename, precData);
      } // all the stuff created in these {} goes out of scope here
      
      
      // output the leaves  as v_ij's)
      {
        std::vector < std::string > colNames;
        colNames.insert(colNames.end(), leavesColNames.begin(), leavesColNames.
      end());
        
        std::vector < RealVec* > data;
        data = addDataPtrs(data, *leavesPtr);
        
        int precData = 10;
        outputToFileVertical(data, colNames, GR_vij_as_Leaves_Filename, 
      precData);
      }
      
      
      //output file for L1
      {
        std::vector < std::string > colNames;
        colNames.push_back("W");
        colNames.push_back("B");
        colNames.push_back("estVarV");
        colNames.push_back("rhat");
        #ifdef MYDEBUG
          colNames.push_back("rhatL1Flag");
          colNames.push_back("sampled?");
        #endif
        std::vector < RealVec* > data;
        data.push_back(Ws_L1Ptr);
        data.push_back(Bs_L1Ptr);
        data.push_back(estVarV_L1Ptr);
        data.push_back(rhat_L1Ptr);
        
        #ifdef MYDEBUG
          data.push_back(rhatL1FlagPtr);
          
          // need to take only some of the sampled states
          RealVecItr it = sampledIndPtr->begin();
          std::advance(it, startFullChecks-1);
          RealVec tmpSampled(it, sampledIndPtr->end());
          
          data.push_back(&tmpSampled);
        #endif
        int precData = 5;
        outputToFileVertical(data, colNames, GRL1Filename, precData);
      } // all the stuff created in these {} goes out of scope here
      
      
      // addition to output the L1 distances (v_ij's)
      {
        std::vector < std::string > colNames;
        colNames.insert(colNames.end(), L1ColNames.begin(), L1ColNames.end());
        
        std::vector < RealVec* > data;
        data = addDataPtrs(data, *distancesL1Ptr);
        
        int precData = 10;
        outputToFileVertical(data, colNames, GR_vij_as_L1_Filename, precData);
      }
      
      
      #ifdef MYDEBUG
      {
        /* output working calcs: all leaves for each chain, 
         * running sums for each chain, sample variances,
         * overall running sums */
        std::vector < std::string > colNames;
        colNames.insert(colNames.end(), leavesColNames.begin(), leavesColNames.
      end());
        colNames.insert(colNames.end(), leavesRunningSumColNames.begin(), 
      leavesRunningSumColNames.end());
        colNames.insert(colNames.end(), leavesSampleVarianceColNames.begin(), 
      leavesSampleVarianceColNames.end());
        colNames.push_back(overallLeavesRunningSumColName);
        
        std::vector < RealVec* > data;
        data = addDataPtrs(data, *leavesPtr);
        data = addDataPtrs(data, *runningSumLeavesChainsPtr);
        data = addDataPtrs(data, *sampleVariancesLeavesPtr);
        data.push_back(runningSumLeavesOverallPtr);
        
        int precData = 10;
        outputToFileVertical(data, colNames, GRLeavesWorkingCalcsFilename, 
      precData);
      
      }
      #endif

      #ifdef MYDEBUG
      {
        /* output working calcs: all L1s for each chain, 
         * running sums for each chain, sample variances,
         * overall running sums */
        std::vector < std::string > colNames;
        colNames.insert(colNames.end(), L1ColNames.begin(), L1ColNames.end());
        colNames.insert(colNames.end(), L1RunningSumColNames.begin(), 
      L1RunningSumColNames.end());
        colNames.insert(colNames.end(), L1SampleVarianceColNames.begin(), 
      L1SampleVarianceColNames.end());
        colNames.push_back(overallL1RunningSumColName);
        
        std::vector < RealVec* > data;
        data = addDataPtrs(data, *distancesL1Ptr);
        data = addDataPtrs(data, *runningSumL1ChainsPtr);
        data = addDataPtrs(data, *sampleVariancesL1Ptr);
        data.push_back(runningSumL1OverallPtr);
        
        int precData = 10;
        outputToFileVertical(data, colNames, GRL1WorkingCalcsFilename, precData
      );
      
      }
      #endif
      
      
      cout << "\n\nFinished MCMC successfully\n" << endl;
      cout << "Check output files\n\t" << GRLeavesFilename
              << "\n\t" << GRL1Filename
              << "\nfor diagnostics" << endl;
      cout << "and for scalar values\n\t" << GR_vij_as_L1_Filename
              << "\n\t" << GR_vij_as_Leaves_Filename << endl;
      if (logging = LOGSAMPLES) {
        cout << "and\t" << samplesLogFilename
            << "\nfor log of samples" <<endl;
      }
      #ifdef MYDEBUG
        cout << "and\t" << GRL1WorkingCalcsFilename
          << "\n\t" << GRLeavesWorkingCalcsFilename
            << "\nfor working calculations for diagnostics" <<endl;
      #endif
      #ifdef MYDEBUG_OUTPUT
        cout << "and\t" << baseSequenceStateCollationFilename << "*.txt, \n\t"
            << baseSequenceStateAverageFilename << "*.txt \n\t"
            << baseSequenceStateDiffsToAverageFilename << "*.txt \n"
            << "for sequence development details" <<endl;
      #endif
      cout << endl;
    }
    
    /* clean up the newed stuff
     * 
     * note that this does not get cleaned up if we throw an exception in the
       while loop
     * - should probably deal with that at some point but all the newed memory
       will be 
     * freed when it terminates anyway so assuming this code is just run as a
       one-off example,
     * it will be okay for the moment */
    
    vector<AdaptiveHistogram*>::iterator ait;
    for (ait = hists.begin(); ait < hists.end(); ++ait) {
      if (NULL != *ait) delete (*ait);
    }

    vector<AdaptiveHistogramCollator*>::iterator acit;
    for (acit = sequenceCollators.begin(); acit < sequenceCollators.end(); ++
      acit) {
      if (NULL != *acit) delete (*acit);
    }
    /*
    for (acit = averageCollators.begin(); acit < averageCollators.end();
       acit++) {
      if (NULL != *acit) delete (*acit);
    }
    */
    delete samplesColl;
    
    #ifdef MYDEBUG
      delete sampledIndPtr;
    #endif
    
    // leaves stuff
    delete leavesPtr;  

    delete runningSumLeavesPtr;
    
    #ifdef MYDEBUG
      delete runningSumLeavesOverallPtr;
      delete runningSumLeavesChainsPtr;
      delete sampleVariancesLeavesPtr;
      delete rhatLeavesFlagPtr;
    #endif

    delete Ws_leavesPtr;
    delete Bs_leavesPtr;
    delete estVarV_leavesPtr;
    delete rhat_leavesPtr;
    
    // L1 stuff
    delete distancesL1Ptr;  

    delete runningSumL1Ptr;
    
    #ifdef MYDEBUG
      delete runningSumL1OverallPtr;
      delete runningSumL1ChainsPtr;
      delete sampleVariancesL1Ptr;
      delete rhatL1FlagPtr;
    #endif

    delete Ws_L1Ptr;
    delete Bs_L1Ptr;
    delete estVarV_L1Ptr;
    delete rhat_L1Ptr;
          
    /* since I throw an exception in the while loop if it is not a good loop,
     *  really the only reason for failing here is that we did not get the
       right 
     * number of samples, but might as well leave it like this - belt & braces
      */      
    if (!cancontinue || (samplesSoFar < samplesNeeded) ) {
      cout << "\nMCMC not successful" << endl;
      cout << "Output files will not be complete - delete or ignore:\n"
          << GRL1Filename
          << "\n" << GRLeavesFilename
          << "\n" << GR_vij_as_L1_Filename
          << "\n" << GR_vij_as_Leaves_Filename << endl;
      
      #ifdef MYDEBUG
        cout << GRL1WorkingCalcsFilename;
        cout << "\n" << GRLeavesWorkingCalcsFilename << endl;
      #endif
      if (logging = LOGSAMPLES) {
        cout << samplesLogFilename << endl;
      }
      #ifdef MYDEBUG_OUTPUT
        cout << baseSequenceStateCollationFilename << "*.txt,"
        << "\n" <<  baseSequenceStateAverageFilename << "*.txt,"
        << "\n" <<  baseSequenceStateDiffsToAverageFilename << "*.txt" << endl;
      #endif
      cout << endl;
      
      if (!cancontinue) {
        throw std::runtime_error("MCMC failed");
      }
      if (samplesSoFar < samplesNeeded) {
        // we have not been able to get the required samples - need to give up
        throw std::runtime_error("Did not get required number of samples");
      }
    }
    
  } // end check on successful insertion of data into histograms
  else {
    throw std::runtime_error("MCMC failed: could not insert data into all
       starting histograms");
  }



    D++; // counter to go through unlabDataVec
  } // end of going through unlabDataVec
  
  //-----------output the estimated likelihood  to .txt file------------//
  string EstLikOut = dirName;
  EstLikOut += "ObsEstLkl.txt";
  os.open(EstLikOut.c_str());
  vector<real>::iterator it;  
  for (it = logLikVec.begin(); it < logLikVec.end(); it++) {
      os << (*it) << endl;
  } 
  os << flush;
  os.close();
  cout << "Likelihood ratios output to " << EstLikOut << endl; 
  cout << "=================================================" << endl;  
  

   //free the random generator
  gsl_rng_free(r);
  
  AdaptiveHistogramCollator coll;
  return coll;
} // end of AHABC
\end{DoxyCode}
\hypertarget{AHABCObsMCMCDblHurdle_8cpp_a0ddf1224851353fc92bfbff6f499fa97}{\index{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp@{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp}!main@{main}}
\index{main@{main}!AHABCObsMCMCDblHurdle.cpp@{\-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp}}
\paragraph[{main}]{\setlength{\rightskip}{0pt plus 5cm}int {\bf main} (
\begin{DoxyParamCaption}
\item[{int}]{argc, }
\item[{char $\ast$}]{argv\mbox{[}$\,$\mbox{]}}
\end{DoxyParamCaption}
)}}\label{AHABCObsMCMCDblHurdle_8cpp_a0ddf1224851353fc92bfbff6f499fa97}


\-Definition at line 65 of file \-A\-H\-A\-B\-C\-Obs\-M\-C\-M\-C\-Dbl\-Hurdle.\-cpp.



\-References do\-M\-C\-M\-C\-G\-R\-Auto(), subpavings\-::output\-File\-Start(), and subpavings\-::\-Adaptive\-Histogram\-Collator\-::output\-To\-Txt\-Tabs().


\begin{DoxyCode}
{
  //--------------input parameters for AHABC--------------------------------//
   //directory to store files in
  string dirName = argv[1];

  // names of files
  string simDataFiles = argv[2]; // this is a row vector of filenames
   string obsDataFile = argv[3];

  //parameters for log-likelihood estimation
  double wt = atof(argv[4]); //mass to ensure positive density 
                     //everywhere in domain
  double dx = atof(argv[5]); //1 for non-atomic densities

   //--------------end of input parameters----------------------------------//

  //========user-defined parameters for MCMC====================//
  int maxLoops = atoi(argv[6]); // maximum changes of state from initial state
       to try
  int samplesNeeded = atoi(argv[7]); // how many samples do we want (ie once
       chains have burned in)
  int thinout = atoi(argv[8]); // sample every thinout state, ie thinout-1
       states between samples
  
  /* note that all chains will be sampled in parallel, once burnin has
       happened,
   * eg if we want 100 samples and have 4 chains and thinout 5, then we will
       sample
   * the last state from each chain as soon as convergence has been achieved 
   * (and thus get 4 samples), and then wait 5-1 = 4 states, and on the 5th,
       again 
   * sample from all 4 chains (assuming that convergence is still okay), etc
       etc
   * so it will take 1 + (100-4)/4*5 = 1 + 25*5 = 1 + 120 = 121 states from
       burnin inclusive
   * of the burnin state itself to get the full sample */

  int minPoints = atoi(argv[9]); //minPoints
  
  cxsc::real tol_leaves(10); //tolerance for automated burn in criteria for
       leaves
  cxsc::real tol_L1(11); //tolerance for automated burn in criteria for L1

  int rhatFlagCounterThreshold = 2;   /* how many of the scalar values must
       have
                      * diagnostic within limits for sampling to start?
                      * usually this would probably be the number
                      * of scalar values being used? */
  int startWithFullChecks = 0; /* indicator for whether we bypass the first
       hurdle
                (the leaves convergence) and go straight to monitoring for 
                actual burnin*/

  //========Hardcoded parameters====================================//
  //int maxLoops = 5000; // maximum changes of state from initial state to try
  //int samplesNeeded = 10; // how many samples do we want (ie once chains have
       burned in)
  //int thinout = 5; // sample every thinout state, ie thinout-1 states between
       samples
  //cxsc::real tol(0.1); //tolerance for automated burn in criteria
  
  // should really do more checks on parameters, but just check thinout here
  if (thinout < 1 ) {
    throw std::invalid_argument("Invalid thinout argument");
  }
  //===========done with working on parameters==========================//
  
  try {
    AdaptiveHistogramCollator avg = doMCMCGRAuto(dirName, simDataFiles,
        obsDataFile, wt, dx,
        maxLoops, samplesNeeded, thinout, minPoints,
        tol_leaves, tol_L1, rhatFlagCounterThreshold, startWithFullChecks);

    std::string samplesCollAverageFilename = dirName;
    samplesCollAverageFilename += "AveragedSamplesFromMCMCGRAuto.txt";
    outputFileStart(samplesCollAverageFilename);
  
    avg.outputToTxtTabs(samplesCollAverageFilename);
    
    return 0;
  }
  catch (std::runtime_error& e) {
    cout << "\nFailed doMCMCGRAuto: original error:\n" 
      << std::string(e.what()) << "\n" << endl;
  }
} 
\end{DoxyCode}
